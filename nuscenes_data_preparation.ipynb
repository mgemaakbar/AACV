{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMpFRnrekrsD",
        "outputId": "72227ab3-e639-46e8-a210-71722f8073f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  609M  100  609M    0     0   100M      0  0:00:06  0:00:06 --:--:--  107M\n"
          ]
        }
      ],
      "source": [
        "#!curl -L https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-all-metadata.tgz > data_annotation.tgz # real annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRqIV408EsG6",
        "outputId": "a702cc2b-e80a-40ab-e07f-96c933b68b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 15.2G  100 15.2G    0     0  14.4M      0  0:17:57  0:17:57 --:--:-- 12.4M\n"
          ]
        }
      ],
      "source": [
        "#!curl -L https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-all-samples.tgz > data_image.tgz # real images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgd5cL_mJrDI"
      },
      "outputs": [],
      "source": [
        "# minified version just for testing\n",
        "#!curl -L https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-mini.tgz > mini.tgz && tar -xzf mini.tgz && mv v1.0-mini v1.0-train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbO9yov1FY7W",
        "outputId": "0a6c658e-9be8-4541-f19d-5f22ed3397b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive # the real images data files take too long (about 17 minutes) to be downloaded, so we just mount it\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsh02yDKJyN1"
      },
      "outputs": [],
      "source": [
        "!tar -xzf /content/drive/MyDrive/nuimages-v1.0-all-metadata.tgz && tar -xzf /content/drive/MyDrive/nuimages-v1.0-all-samples.tgz # extract. this will take about 7 minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CB-rhXD_6PcX"
      },
      "outputs": [],
      "source": [
        "drive.flush_and_unmount() # unmount when we don't need it anymore, so we have more disk space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-idcf2kQgin0"
      },
      "outputs": [],
      "source": [
        "!mkdir train test val && mkdir train/image test/image val/image train/label test/label val/label # for the yolo format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrYkgnkaj8Gf",
        "outputId": "08c85df9-17de-42a5-ff9a-eb569e9179f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "136074\n",
            "213185\n",
            "25\n",
            "557715\n",
            "872181\n",
            "25\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def bbox_to_yolo(xmin, ymin, xmax, ymax, image_width, image_height):\n",
        "    box_width = xmax - xmin\n",
        "    box_height = ymax - ymin\n",
        "\n",
        "    x_center = xmin + box_width / 2\n",
        "    y_center = ymin + box_height / 2\n",
        "\n",
        "    # Normalize by image size\n",
        "    x_center_norm = x_center / image_width\n",
        "    y_center_norm = y_center / image_height\n",
        "    width_norm = box_width / image_width\n",
        "    height_norm = box_height / image_height\n",
        "\n",
        "    return x_center_norm, y_center_norm, width_norm, height_norm\n",
        "\n",
        "\n",
        "def read_and_join(path_prefix):\n",
        "    obj_ann = pd.read_json(path_prefix + 'object_ann.json')\n",
        "    category = pd.read_json(path_prefix + 'category.json').rename(columns={\"name\": \"category_name\"})\n",
        "    category['category_id'] = range(len(category))\n",
        "    sample_data = pd.read_json(path_prefix + 'sample_data.json')\n",
        "    # attribute = pd.read_json(path_prefix + 'attribute.json')\n",
        "\n",
        "    # object annotation left join sample_data\n",
        "    merged = obj_ann.merge(\n",
        "        sample_data,\n",
        "        how = 'left',\n",
        "        right_on='token',\n",
        "        left_on='sample_data_token',\n",
        "        suffixes=('_left', '_right')\n",
        "    )\n",
        "\n",
        "    merged = merged.merge(\n",
        "        category,\n",
        "        how = 'left',\n",
        "        left_on='category_token',\n",
        "        right_on='token',\n",
        "        suffixes=('_from_merged', '_from_category')\n",
        "    )\n",
        "\n",
        "    print (len(obj_ann))\n",
        "    print (len(sample_data))\n",
        "    print (len(category))\n",
        "\n",
        "    return merged\n",
        "\n",
        "# create list of train/val/test image file name list in a txt file (train/val.txt), so we can use cp/rsync with it\n",
        "def create_image_filename_list(path_prefix, data_split, merged):\n",
        "    if data_split not in ['train', 'val', 'test']:\n",
        "        return -1\n",
        "\n",
        "    df = merged[['filename']]\n",
        "    filenames = set([])\n",
        "    for index, row in df.iterrows():\n",
        "        filenames.add(row['filename'])\n",
        "    for fn in filenames:\n",
        "        with open(data_split+\".txt\", 'a') as f:\n",
        "            f.write(fn + \"\\n\")\n",
        "\n",
        "# create yolo label txt\n",
        "def convert_to_yolo_format(path_prefix, data_split, merged):\n",
        "    if data_split not in ['train', 'val', 'test']:\n",
        "        return -1\n",
        "    df = merged[['bbox', 'category_id', 'category_name', 'filename', 'width',  'height']]\n",
        "    for index, row in df.iterrows():\n",
        "        filename = row['filename'].split(\"/\")[-1] # filename column is in the format of samples/CAM_BACK/n010-2018-08-27-16-15-24+0800...\n",
        "        abs_path_to_label_txt = path_prefix + data_split + \"/label/\" + filename + '.txt' # example: /content/train/label/asdf.jpg.txt\n",
        "        x_center, y_center, width, height = bbox_to_yolo(row['bbox'][0], row['bbox'][1], row['bbox'][2], row['bbox'][3], row['width'], row['height'])\n",
        "        with open(abs_path_to_label_txt, 'a') as f: # append label to the txt\n",
        "            f.write(str(row['category_id']) + \" \" + str(x_center) + \" \" + str(y_center) + \" \" + str(width) + \" \" + str(height) + \"\\n\")\n",
        "\n",
        "path_prefix = '/content/v1.0-val.'\n",
        "val_df = read_and_join('/content/v1.0-val/')\n",
        "train_df = read_and_join('/content/v1.0-train/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-CPubGQTR8e"
      },
      "outputs": [],
      "source": [
        "create_image_filename_list('/content/', 'train', train_df)\n",
        "create_image_filename_list('/content/', 'val', val_df)\n",
        "convert_to_yolo_format('/content/', 'train', train_df)\n",
        "convert_to_yolo_format('/content/', 'val', val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0NYNGBBhMKV"
      },
      "outputs": [],
      "source": [
        "# make sure the val.txt exists before running this\n",
        "# copy the val image to directory expected by yolo. should take about 1 minute\n",
        "!xargs -a val.txt -P8 -I{} cp \"/content/{}\" /content/val/image/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjXD2rRkixcr"
      },
      "outputs": [],
      "source": [
        "# make sure the train.txt exists before running this\n",
        "# copy the train image to directory expected by yolo. should take about 5 minutes\n",
        "!xargs -a train.txt -P8 -I{} cp \"/content/{}\" /content/train/image/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "VgnYFY6ILXtU",
        "outputId": "c12ad747-2d2a-43c4-eb00-9b620259926b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>samples/CAM_BACK/n010-2018-08-27-16-15-24+0800...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>samples/CAM_BACK_LEFT/n009-2018-09-12-09-59-51...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>samples/CAM_BACK/n003-2018-01-08-11-30-34+0800...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>samples/CAM_FRONT_RIGHT/n008-2018-05-24-12-02-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>samples/CAM_FRONT_RIGHT/n014-2018-06-20-21-35-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "0    samples/CAM_BACK/n010-2018-08-27-16-15-24+0800...\n",
              "1    samples/CAM_BACK_LEFT/n009-2018-09-12-09-59-51...\n",
              "2    samples/CAM_BACK/n003-2018-01-08-11-30-34+0800...\n",
              "3    samples/CAM_FRONT_RIGHT/n008-2018-05-24-12-02-...\n",
              "4    samples/CAM_FRONT_RIGHT/n014-2018-06-20-21-35-...\n",
              "Name: filename, dtype: object"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df['filename'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do5XNsKxSZgF",
        "outputId": "b7925980-40b8-4488-87bd-f2acda227279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60668\n"
          ]
        }
      ],
      "source": [
        "!ls -1 /content/train/image/ | wc -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VxYfx-WSwx3",
        "outputId": "67b70241-c194-4855-8900-eeb991588f62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60668\n"
          ]
        }
      ],
      "source": [
        "!ls -1 /content/train/label/ | wc -l"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
